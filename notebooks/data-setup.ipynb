{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import io\n",
    "from torchvision import transforms\n",
    "import json\n",
    "\n",
    "data_source_name = \"NeRF_Data\"\n",
    "dataset_name = \"nerf_synthetic\"\n",
    "scene_name = \"lego\"\n",
    "\n",
    "root_data_dir = pl.Path('./data/')\n",
    "data_path = root_data_dir / data_source_name / dataset_name / scene_name\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.data import FrameDataset\n",
    "\n",
    "digit_pattern = re.compile(r\"\\d+\")\n",
    "\n",
    "   \n",
    "train_dataset = FrameDataset(data_path, \"train\")\n",
    "\n",
    "print(train_dataset.ex_img.shape)\n",
    "print(train_dataset.ex_img[0].max(), train_dataset.ex_img[3].max())\n",
    "plt.imshow(train_dataset.ex_img.T.swapaxes(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import get_rays\n",
    "\n",
    "H, W = train_dataset.shape\n",
    "focal = train_dataset.focal\n",
    "c2w = train_dataset.transform_matrixes[5]\n",
    "\n",
    "rays_d, rays_o = get_rays(H, W, focal, c2w)\n",
    "rays_d.shape, rays_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H, W = 8, 8\n",
    "L1 = 10\n",
    "L2 = 4\n",
    "D = 3\n",
    "\n",
    "batch_size = 1\n",
    "n_bins = 5\n",
    "n_rays = H * W\n",
    "n_samples = n_bins * n_rays\n",
    "\n",
    "t_near = 0.1\n",
    "t_far = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import positional_encoding\n",
    "\n",
    "tmp_o = torch.randn(batch_size * n_samples * D,device=DEVICE).reshape(batch_size, n_rays, n_bins, D)\n",
    "tmp_d = torch.randn(batch_size * n_samples * D,device=DEVICE).reshape(batch_size, n_rays, n_bins, D)\n",
    "tex = positional_encoding(tmp_o, L1)\n",
    "ted = positional_encoding(tmp_o, L2)\n",
    "\n",
    "tex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import TestNet\n",
    "\n",
    "tn = TestNet(L1, L2, 3, 128)\n",
    "#tmp_c, tmp_sigma = tn(tex, ted)\n",
    "#tmp_c.shape, tmp_sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import get_t\n",
    "\n",
    "tmp_t, tmp_dt = get_t(batch_size, n_rays, n_bins, t_near, t_far)\n",
    "tmp_t.shape, tmp_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import expected_color\n",
    "\n",
    "#tmp_c_hat = expected_color(tmp_c, tmp_sigma, tmp_dt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import RayDataset\n",
    "\n",
    "train_render_dataset = RayDataset(train_dataset)\n",
    "train_render_loader = DataLoader(train_render_dataset, batch_size=batch_size, shuffle=False,num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_o, r_d, C_r = next(iter(train_render_dataset))\n",
    "r_o = r_o[None, ...].to(DEVICE)\n",
    "r_d = r_d[None, ...].to(DEVICE)\n",
    "C_r = C_r[None, ...].to(DEVICE)\n",
    "\n",
    "def strat_sampling(N: int, t_near: float, t_far: float) -> torch.Tensor:\n",
    "    samples = (torch.arange(N,device=DEVICE) + torch.rand(N,device=DEVICE)) * (t_far - t_near) / N  # <N>\n",
    "    return samples\n",
    "\n",
    "\n",
    "def get_t(batch_size, n_rays, n_bins, t_near, t_far) -> torch.Tensor:\n",
    "    t = strat_sampling(batch_size * n_rays * n_bins, t_near, t_far).reshape(\n",
    "        batch_size, n_rays, n_bins\n",
    "    )\n",
    "    dt = torch.diff(t, dim=-1)\n",
    "    return t, dt\n",
    "\n",
    "B = r_o.size(0)\n",
    "t, dt = get_t(B, n_rays, n_bins, t_near, t_far)\n",
    "\n",
    "r_d = nn.functional.normalize(r_d, dim=-1)\n",
    "\n",
    "r_o = r_o.reshape(B, -1, 1, 3)\n",
    "r_d = r_d.reshape(B, -1, 1, 3)\n",
    "t = t[..., None]\n",
    "\n",
    "\n",
    "pts = r_o + t * r_d\n",
    "pts, r_d\n",
    "print(pts.shape, r_d.shape)\n",
    "\n",
    "ex = positional_encoding(pts, L1)\n",
    "ed = positional_encoding(r_d, L2)\n",
    "\n",
    "print(ex.shape, ed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import LitNerf\n",
    "\n",
    "nerf = LitNerf(tn, n_rays, n_bins, t_near, t_far, L1, L2, learning_rate=3e-4).to(DEVICE)\n",
    "#nerf.training_step(next(iter(train_render_loader)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as ptl\n",
    "\n",
    "trainer = ptl.Trainer(max_epochs=10)\n",
    "trainer.fit(nerf, train_dataloaders=train_render_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
